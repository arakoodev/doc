"use strict";(self.webpackChunkalekhaweb=self.webpackChunkalekhaweb||[]).push([[8901],{3905:(e,n,t)=>{t.d(n,{Zo:()=>d,kt:()=>u});var a=t(7294);function i(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function r(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){i(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,a,i=function(e,n){if(null==e)return{};var t,a,i={},o=Object.keys(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||(i[t]=e[t]);return i}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(i[t]=e[t])}return i}var p=a.createContext({}),l=function(e){var n=a.useContext(p),t=n;return e&&(t="function"==typeof e?e(n):r(r({},n),e)),t},d=function(e){var n=l(e.components);return a.createElement(p.Provider,{value:n},e.children)},c="mdxType",h={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},m=a.forwardRef((function(e,n){var t=e.components,i=e.mdxType,o=e.originalType,p=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),c=l(t),m=i,u=c["".concat(p,".").concat(m)]||c[m]||h[m]||o;return t?a.createElement(u,r(r({ref:n},d),{},{components:t})):a.createElement(u,r({ref:n},d))}));function u(e,n){var t=arguments,i=n&&n.mdxType;if("string"==typeof e||i){var o=t.length,r=new Array(o);r[0]=m;var s={};for(var p in n)hasOwnProperty.call(n,p)&&(s[p]=n[p]);s.originalType=e,s[c]="string"==typeof e?e:i,r[1]=s;for(var l=2;l<o;l++)r[l]=t[l];return a.createElement.apply(null,r)}return a.createElement.apply(null,t)}m.displayName="MDXCreateElement"},2222:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>p,contentTitle:()=>r,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>l});var a=t(7462),i=(t(7294),t(3905));const o={slug:"Semantic-Search",title:"How to Build Semantic Search using EdgeChains",authors:{name:"Aditya Pandey",title:"Arakoo Core Team",url:"https://github.com/arakoodev",image_url:"https://avatars.githubusercontent.com/u/114422989"},tags:["Semantic Search","Arakoo"]},r="How to Build Semantic Search using EdgeChains.",s={permalink:"/blog/Semantic-Search",editUrl:"https://github.com/arakoodev/doc/tree/main/blog/2023-09-16-semantic-search/index.md",source:"@site/blog/2023-09-16-semantic-search/index.md",title:"How to Build Semantic Search using EdgeChains",description:"Search for your document from a large pack of existing documents in the most effective manner.",date:"2023-09-16T00:00:00.000Z",formattedDate:"September 16, 2023",tags:[{label:"Semantic Search",permalink:"/blog/tags/semantic-search"},{label:"Arakoo",permalink:"/blog/tags/arakoo"}],readingTime:12.265,hasTruncateMarker:!1,authors:[{name:"Aditya Pandey",title:"Arakoo Core Team",url:"https://github.com/arakoodev",image_url:"https://avatars.githubusercontent.com/u/114422989",imageURL:"https://avatars.githubusercontent.com/u/114422989"}],frontMatter:{slug:"Semantic-Search",title:"How to Build Semantic Search using EdgeChains",authors:{name:"Aditya Pandey",title:"Arakoo Core Team",url:"https://github.com/arakoodev",image_url:"https://avatars.githubusercontent.com/u/114422989",imageURL:"https://avatars.githubusercontent.com/u/114422989"},tags:["Semantic Search","Arakoo"]},prevItem:{title:"How to Build a Article Writer Prompt with EdgeChains",permalink:"/blog/Article-writer"},nextItem:{title:"Getting Started with Supabase",permalink:"/blog/Supabase"}},p={authorsImageUrls:[void 0]},l=[{value:"Pre Requisites",id:"pre-requisites",level:3},{value:"Configuration of the Database:",id:"configuration-of-the-database",level:3},{value:"Explanation of the Code",id:"explanation-of-the-code",level:3},{value:"Upsert Controller",id:"upsert-controller",level:3},{value:"Query Controller",id:"query-controller",level:3},{value:"Postman Testing",id:"postman-testing",level:3},{value:"JSONnet for the Code",id:"jsonnet-for-the-code",level:2}],d={toc:l},c="wrapper";function h(e){let{components:n,...o}=e;return(0,i.kt)(c,(0,a.Z)({},d,o,{components:n,mdxType:"MDXLayout"}),(0,i.kt)("p",null,"Search for your document from a large pack of existing documents in the most effective manner."),(0,i.kt)("p",null,"Consider you have a notice of opening of campus of some Institute :",(0,i.kt)("br",{parentName:"p"}),"\n","You want to find a particular campus that is similar to some campuses of Kolkata. The best effective way to do so would be by using the Semantic Search."),(0,i.kt)("p",null,"Semantic Search is the task of retrieving the documents from a collection of the documents in response to a query asked .It allows you to access the best matches from your document collection within seconds and the best thing is the fact is on the basis of meaning rather than keyword matches .A Semantic Search model has been created using Java.",(0,i.kt)("br",{parentName:"p"}),"\n",(0,i.kt)("a",{parentName:"p",href:"https://github.com/arakoodev/edgechains"},"Edgechains")," is a streamlined solution for developing GenAI applications, offering simplicity through a single script file and jsonnet file setup. It emphasizes versioning for prompts, automatic parallelism across various processors, fault tolerance, and scalability, making it a robust choice for chain-of-thought applications with extensive API integration and data sets. While Langchain primarily focuses on a specific set of principles, EdgeChains takes a unique stance, emphasizing declarative prompt and chain orchestration as pivotal components of its architecture. To delve deeper into EdgeChains and explore its capabilities, you can refer to our ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/arakoodev/edgechains#why-do-you-need-declarative-prompt--chain-orchestration-"},"GitHub repository")," . "),(0,i.kt)("h3",{id:"pre-requisites"},"Pre Requisites"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"You need to make an account in OPENAI, Pinecone, Postgres so that from there you can retrieve the auth key, org id and etc which are needed for the code.  "),(0,i.kt)("li",{parentName:"ol"},"You need to download the edgechains jar file from this url ",(0,i.kt)("a",{parentName:"li",href:"https://github.com/arakoodev/EdgeChains/releases"},"https://github.com/arakoodev/EdgeChains/releases"),".  "),(0,i.kt)("li",{parentName:"ol"},"Download the ",(0,i.kt)("inlineCode",{parentName:"li"},".java")," and ",(0,i.kt)("inlineCode",{parentName:"li"},".jsonnet")," file and put them in the same folder.  "),(0,i.kt)("li",{parentName:"ol"},"In the code according to the folder structure you have to write about the path.  ")),(0,i.kt)("h3",{id:"configuration-of-the-database"},"Configuration of the Database:"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"Go to the Supabase website (",(0,i.kt)("a",{parentName:"li",href:"https://supabase.io"},"https://supabase.io"),") and sign up for an account."),(0,i.kt)("li",{parentName:"ol"},"Create a new Project by clicking the \u201cNew Project\u201d button."),(0,i.kt)("li",{parentName:"ol"},"Configure your project settings including the project name, region, and the plan."),(0,i.kt)("li",{parentName:"ol"},"Once your project is created, you\u2019ll be directed to the project dashboard."),(0,i.kt)("li",{parentName:"ol"},"Click the \u201cCreate Database\u201d button to create a new PostgreSQL database."),(0,i.kt)("li",{parentName:"ol"},"After the database is created, you can access its credentials, including the database URL, API URL and service role key.  ")),(0,i.kt)("h3",{id:"explanation-of-the-code"},"Explanation of the Code"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Load the edgechains package.  ")),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Import the OPENAI_Chat_Completion API. Here we have to import the static constants from other classes. These classes are Pinecone, OpenAI, and PDF reading.  ")),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Import the Spring Framework related classes and annotations.",(0,i.kt)("br",{parentName:"p"}),"\n",(0,i.kt)("img",{alt:"Spring Page",src:t(2381).Z,width:"1275",height:"109"}))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Fill in the details of the ",(0,i.kt)("inlineCode",{parentName:"p"},"auth key"),", ",(0,i.kt)("inlineCode",{parentName:"p"},"org_id")," and others of OpenAI and Pinecone.",(0,i.kt)("br",{parentName:"p"}),"\n",(0,i.kt)("img",{alt:"OpenAI Page",src:t(5100).Z,width:"1762",height:"960"}))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Create variables that may be interacting with the OpenAI services used to store authentication keys and API endpoints.  ")),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Load the jsonnet file into the variable, and then load the data of that file into the variable.  ")),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"In the main method, set the system server port to the desired port or by default it is ",(0,i.kt)("inlineCode",{parentName:"p"},"8080"),". ",(0,i.kt)("inlineCode",{parentName:"p"},"Properties properties = new Properties ();")," this property is often used in Java to manage the key-value pairs.  ")),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Then you have to configure the Hibernate to format the SQL queries for better readability. The lines written below are used to access the database. They enable SQL query logging and formatting in Spring JPA (Java Persistence API).\n",(0,i.kt)("img",{alt:"CORS Page",src:t(3338).Z,width:"997",height:"110"}))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Set the CORS (Cross-Origin Resource Sharing) by specifying the allowed origins.  ")),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Then you have to initialize several endpoints and related configurations.  "))),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"ada002Embedding"),": This variable is an instance of the ",(0,i.kt)("inlineCode",{parentName:"li"},"OpenAiEndpoint")," class, which is used to interact with OpenAI for text embeddings.  It is a configuration object that allows your Java code to communicate with OpenAI's text embedding service using the ",(0,i.kt)("strong",{parentName:"li"},(0,i.kt)("em",{parentName:"strong"},'"Ada 002"'))," model and handle authentication and retry logic. It's a part of integrating OpenAI's capabilities into your application for NLP tasks.  "),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"gpt3Endpoint"),": This variable is another instance of the OpenAiEndpoint class, configured for GPT-3.5 Turbo, a language model for chat completions. It has similar configuration parameters as ada002Embedding but with additional settings for chat completions.  It is a configuration object that facilitates communication with OpenAI's ",(0,i.kt)("strong",{parentName:"li"},(0,i.kt)("em",{parentName:"strong"},'"GPT-3.5 Turbo"'))," model for chat-based language generation tasks. "),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"upsertPineconeEndpoint"),": This variable is an instance of the ",(0,i.kt)("inlineCode",{parentName:"li"},"PineconeEndpoint")," class, which is used to interact with Pinecone for upserting vectors. It is a configuration object that enables your application to interact with the Pinecone service for adding or updating vectors in a vector index. It plays a crucial role in enabling similarity-based search and retrieval functionality in your application.",(0,i.kt)("br",{parentName:"li"}),"These variables are essential for communicating with external services such as OpenAI and Pinecone.",(0,i.kt)("br",{parentName:"li"}),(0,i.kt)("img",{alt:"Endpoint Page",src:t(3892).Z,width:"1111",height:"165"}))),(0,i.kt)("ol",{start:11},(0,i.kt)("li",{parentName:"ol"},"After this, define a Spring class which is responsible for handling the HTTP requests and contains various methods for interacting with Pinecone and OpenAI services."),(0,i.kt)("li",{parentName:"ol"},"Inject a ",(0,i.kt)("inlineCode",{parentName:"li"},"PdfReader")," instance into the controller so that it can be used to read PDF files in the code. ")),(0,i.kt)("h3",{id:"upsert-controller"},"Upsert Controller"),(0,i.kt)("p",null,"Create a method ",(0,i.kt)("inlineCode",{parentName:"p"},"upsertPinecone")," that handles HTTP POST requests to the endpoint which takes an ",(0,i.kt)("inlineCode",{parentName:"p"},"ArkRequest")," object as a parameter which contains data required for the operation. Here ",(0,i.kt)("inlineCode",{parentName:"p"},"pdfReader")," is used to read the input stream in chunks of 512 bytes and stores the result in a string array. An instance of ",(0,i.kt)("inlineCode",{parentName:"p"},"PineconeRetrieval")," is created passing the string array created, the ",(0,i.kt)("inlineCode",{parentName:"p"},"ada002Embedding")," endpoint, the ",(0,i.kt)("inlineCode",{parentName:"p"},"upsertPineconeEndpoint")," and the ",(0,i.kt)("inlineCode",{parentName:"p"},"arkRequest"),". The ",(0,i.kt)("inlineCode",{parentName:"p"},"upsert")," method of the ",(0,i.kt)("inlineCode",{parentName:"p"},"PineconeRetrieval")," instance is called to upsert the data into Pinecone. The pdf that you uploaded is divided into chunks and then the embedding vector sends that to the embedding endpoint to perform the similarity search on the query sent.\n",(0,i.kt)("strong",{parentName:"p"},"NOTE"),": Upsert is done only once as you can upload as many pdf files one at a time as after upserting the major work you would be doing is querying.",(0,i.kt)("br",{parentName:"p"}),"\n",(0,i.kt)("img",{alt:"Upsert Page",src:t(4955).Z,width:"1350",height:"357"})),(0,i.kt)("h3",{id:"query-controller"},"Query Controller"),(0,i.kt)("p",null,"Define a method \u2018query\u2019 to handle HTTP POST requests to the ",(0,i.kt)("inlineCode",{parentName:"p"},"/pinecone/query")," endpoint. It extracts the various parameters such as ",(0,i.kt)("inlineCode",{parentName:"p"},"namespace"),", ",(0,i.kt)("inlineCode",{parentName:"p"},"query")," from the ",(0,i.kt)("inlineCode",{parentName:"p"},"arkRequest")," object. Here EdgeChain performs a Pinecone query using the ",(0,i.kt)("inlineCode",{parentName:"p"},"queryPineconeEndpoint")," and retrieves word embeddings. This helps in transforming the results of the query into a list of the objects using a method. It returns the response containing the result of the query. ",(0,i.kt)("inlineCode",{parentName:"p"},"topk")," is used to divide the pdf into chunks.",(0,i.kt)("br",{parentName:"p"}),"\n",(0,i.kt)("img",{alt:"Query Page",src:t(2441).Z,width:"1293",height:"386"}),(0,i.kt)("br",{parentName:"p"}),"\n","Overall this model manages the interaction with Pinecone and OpenAI services including upserting data, querying based on the received HTTP requests."),(0,i.kt)("h3",{id:"postman-testing"},"Postman Testing"),(0,i.kt)("p",null,"After all this we will be using the postman to test and give the requests for the same in the following manner:  "),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("strong",{parentName:"li"},"Upsert"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Description: Upload a file to update Open AI data in the Pinecone namespace."),(0,i.kt)("li",{parentName:"ul"},"Method: POST"),(0,i.kt)("li",{parentName:"ul"},"URL:",(0,i.kt)("a",{parentName:"li",href:"http://localhost:8080/pinecone/upsert?namespace=machine-learning"},"http://localhost:8080/pinecone/upsert?namespace=machine-learning")),(0,i.kt)("li",{parentName:"ul"},"Headers: Content-Type: multipart/form-data"),(0,i.kt)("li",{parentName:"ul"},"Body:  ",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Mode: formdata  "),(0,i.kt)("li",{parentName:"ul"},"Key: file  "),(0,i.kt)("li",{parentName:"ul"},"Type: file")))))),(0,i.kt)("p",null,"Also one of the important to consider while uploading the files, upload only in pdf format, json format is not allowed. You can only upload one pdf file at a time."),(0,i.kt)("ol",{start:2},(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("strong",{parentName:"p"},"Query")),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Description: Perform a query to retrieve results from Open AI in the Pinecone namespace."),(0,i.kt)("li",{parentName:"ul"},"Method: POST"),(0,i.kt)("li",{parentName:"ul"},"URL:http://localhost:8080/pinecone/query?topK=6&namespace=machine-learning"),(0,i.kt)("li",{parentName:"ul"},"Headers: Content-Type: application/json  "),(0,i.kt)("li",{parentName:"ul"},"Body:  ")),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre"},"* Mode: raw  \n")),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Data:  ",(0,i.kt)("inlineCode",{parentName:"li"},'{"query": "When is the Kolkata campus opening?"  }'))))),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Postman Page",src:t(8633).Z,width:"1244",height:"639"})),(0,i.kt)("p",null,"Semantic Search can change the way searching, ranking or retrieval systems work with their ability to index and store embedding vectors. Here EdgeChain helps in inserting the chunk and calculating the embedding vector. It provides methods which make it very easy for the customer so that they have just to write the business logic and their work happens easily, instead EdgeChain does everything. It ranks according to the score where the score is according to how close their similarity is with the query. And the model will return the answer of the query according to the ranking."),(0,i.kt)("p",null,"The Full Working Code of the Model is.  "),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"},'package com.edgechain;\n\n  \n\nimport  static com.edgechain.lib.constants.EndpointConstants.OPENAI_CHAT_COMPLETION_API;\n\nimport  static com.edgechain.lib.constants.EndpointConstants.OPENAI_EMBEDDINGS_API;\n\n  \n\nimport com.edgechain.lib.chains.PineconeRetrieval;\n\nimport com.edgechain.lib.context.domain.HistoryContext;\n\nimport com.edgechain.lib.embeddings.WordEmbeddings;\n\nimport com.edgechain.lib.endpoint.impl.OpenAiEndpoint;\n\nimport com.edgechain.lib.endpoint.impl.PineconeEndpoint;\n\nimport com.edgechain.lib.endpoint.impl.RedisHistoryContextEndpoint;\n\nimport com.edgechain.lib.jsonnet.JsonnetArgs;\n\nimport com.edgechain.lib.jsonnet.JsonnetLoader;\n\nimport com.edgechain.lib.jsonnet.enums.DataType;\n\nimport com.edgechain.lib.jsonnet.impl.FileJsonnetLoader;\n\nimport com.edgechain.lib.openai.response.ChatCompletionResponse;\n\nimport com.edgechain.lib.reader.impl.PdfReader;\n\nimport com.edgechain.lib.request.ArkRequest;\n\nimport com.edgechain.lib.response.ArkResponse;\n\nimport com.edgechain.lib.rxjava.retry.impl.ExponentialDelay;\n\nimport com.edgechain.lib.rxjava.retry.impl.FixedDelay;\n\nimport com.edgechain.lib.rxjava.transformer.observable.EdgeChain;\n\nimport java.io.IOException;\n\nimport java.io.InputStream;\n\nimport java.util.*;\n\nimport java.util.concurrent.TimeUnit;\n\nimport org.springframework.beans.factory.annotation.Autowired;\n\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\n\nimport org.springframework.boot.builder.SpringApplicationBuilder;\n\nimport org.springframework.web.bind.annotation.*;\n\n  \n\n@SpringBootApplication\n\npublic  class PineconeExample {\n\n  \n\nprivate  static  final String OPENAI_AUTH_KEY = ""; // YOUR OPENAI AUTH KEY\n\nprivate  static  final String OPENAI_ORG_ID = ""; // YOUR OPENAI ORG ID\n\nprivate  static  final String PINECONE_AUTH_KEY = "";\n\nprivate  static  final String PINECONE_QUERY_API = "";\n\nprivate  static  final String PINECONE_UPSERT_API = "";\n\nprivate  static  final String PINECONE_DELETE = "";\n\n  \n\nprivate  static OpenAiEndpoint ada002Embedding;\n\nprivate  static OpenAiEndpoint gpt3Endpoint;\n\n  \n\nprivate  static PineconeEndpoint upsertPineconeEndpoint;\n\nprivate  static PineconeEndpoint queryPineconeEndpoint;\n\n  \n\nprivate  static PineconeEndpoint deletePineconeEndpoint;\n\n  \n\nprivate  static RedisHistoryContextEndpoint contextEndpoint;\n\n  \n\nprivate JsonnetLoader queryLoader = new FileJsonnetLoader("./pinecone-query.jsonnet");\n\nprivate JsonnetLoader chatLoader = new FileJsonnetLoader("./pinecone-chat.jsonnet");\n\n  \n\npublic  static  void main(String[] args) {\n\nSystem.setProperty("server.port", "8080");\n\nProperties properties = new Properties();\n\n  \n\nproperties.setProperty("spring.jpa.show-sql", "true");\n\nproperties.setProperty("spring.jpa.properties.hibernate.format_sql", "true");\n\n  \n\n// Adding Cors ==> You can configure multiple cors w.r.t your urls.;\n\nproperties.setProperty("cors.origins", "http://localhost:4200");\n\n  \n\n// Redis Configuration\n\n/*properties.setProperty("redis.url", "");\n\nproperties.setProperty("redis.port", "");\n\nproperties.setProperty("redis.username", "default");\n\nproperties.setProperty("redis.password", "");\n\nproperties.setProperty("redis.ttl", "3600");*/\n\n  \n\n// If you want to use PostgreSQL only; then just provide dbHost, dbUsername & dbPassword.\n\n// If you haven\'t specified PostgreSQL, then logs won\'t be stored.\n\nproperties.setProperty("postgres.db.host", "");\n\nproperties.setProperty("postgres.db.username", "");\n\nproperties.setProperty("postgres.db.password", "");\n\n  \n\nnew SpringApplicationBuilder(PineconeExample.class).properties(properties).run(args);\n\n  \n\n// Variables Initialization ==> Endpoints must be intialized in main method...\n\nada002Embedding =\n\nnew OpenAiEndpoint(\n\nOPENAI_EMBEDDINGS_API,\n\nOPENAI_AUTH_KEY,\n\nOPENAI_ORG_ID,\n\n"text-embedding-ada-002",\n\nnew ExponentialDelay(3, 3, 2, TimeUnit.SECONDS));\n\n  \n\ngpt3Endpoint =\n\nnew OpenAiEndpoint(\n\nOPENAI_CHAT_COMPLETION_API,\n\nOPENAI_AUTH_KEY,\n\nOPENAI_ORG_ID,\n\n"gpt-3.5-turbo",\n\n"user",\n\n0.85,\n\nnew ExponentialDelay(3, 5, 2, TimeUnit.SECONDS));\n\n  \n\nupsertPineconeEndpoint =\n\nnew PineconeEndpoint(\n\nPINECONE_UPSERT_API,\n\nPINECONE_AUTH_KEY,\n\nnew ExponentialDelay(3, 3, 2, TimeUnit.SECONDS));\n\n  \n\nqueryPineconeEndpoint =\n\nnew PineconeEndpoint(\n\nPINECONE_QUERY_API, PINECONE_AUTH_KEY, new ExponentialDelay(3, 3, 2, TimeUnit.SECONDS));\n\n  \n\ndeletePineconeEndpoint =\n\nnew PineconeEndpoint(\n\nPINECONE_DELETE, PINECONE_AUTH_KEY, new FixedDelay(4, 5, TimeUnit.SECONDS));\n\n  \n\ncontextEndpoint =\n\nnew RedisHistoryContextEndpoint(new ExponentialDelay(2, 2, 2, TimeUnit.SECONDS));\n\n}\n\n  \n\n/**\n\n* By Default, every API is unauthenticated & exposed without any sort of authentication; To\n\n* authenticate, your custom APIs in Controller you would need @PreAuthorize(hasAuthority(""));\n\n* this will authenticate by JWT having two fields: a) email, b) role:"authenticated,user_create"\n\n* To authenticate, internal APIs related to historyContext & Logging, Delete Redis/Postgres we\n\n* need to create bean of AuthFilter; you can uncomment the code. Note, you need to define\n\n* "jwt.secret" property as well to decode accessToken.\n\n*/\n\n// @Bean\n\n// @Primary\n\n// public AuthFilter authFilter() {\n\n// AuthFilter filter = new AuthFilter();\n\n// // ======== new MethodAuthentication(List.of(APIs), authorities) =============\n\n// filter.setRequestPost(new MethodAuthentication(List.of("/v1/postgresql/historycontext"),\n\n// "authenticated")); // define multiple roles by comma\n\n// filter.setRequestGet(new MethodAuthentication(List.of(""), ""));\n\n// filter.setRequestDelete(new MethodAuthentication(List.of(""), ""));\n\n// filter.setRequestPatch(new MethodAuthentication(List.of(""), ""));\n\n// filter.setRequestPut(new MethodAuthentication(List.of(""), ""));\n\n// return filter;\n\n// }\n\n  \n\n@RestController\n\npublic  class PineconeController {\n\n  \n\n@Autowired  private PdfReader pdfReader;\n\n  \n\n/********************** PINECONE WITH OPENAI ****************************/\n\n  \n\n/**\n\n* Namespace: VectorDb allows you to partition the vectors in an index into namespaces. Queries\n\n* and other operations are then limited to one namespace, so different requests can search\n\n* different subsets of your index. If namespace is null or empty, in pinecone it will be\n\n* prefixed as "" empty string & in redis it will be prefixed as "knowledge" For example, you\n\n* might want to define a namespace for indexing books by finance, law, medicine etc.. Can be\n\n* used in multiple use-cases.... such as User uploading book, generating unique namespace &\n\n* then querying/chatting with it..\n\n*\n\n* @param arkRequest\n\n* @return\n\n*/\n\n// Namespace is optional (if not provided, it will be using Empty String "")\n\n@PostMapping("/pinecone/upsert") // /v1/examples/openai/upsert?namespace=machine-learning\n\npublic  void upsertPinecone(ArkRequest arkRequest) throws IOException {\n\n  \n\n// String namespace = arkRequest.getQueryParam("namespace");\n\nInputStream file = arkRequest.getMultiPart("file").getInputStream();\n\n  \n\n// Configure Pinecone\n\n// upsertPineconeEndpoint.setNamespace(namespace);\n\n  \n\nString[] arr = pdfReader.readByChunkSize(file, 512);\n\n  \n\n/**\n\nRetrieval Class is basically used to generate embeddings & upsert it to VectorDB; If OpenAI\n\nEmbedding Endpoint is not provided; then Doc2Vec constructor is used If the model is not\n\nprovided, then it will emit an error*/\n\nPineconeRetrieval retrieval =\n\nnew PineconeRetrieval(arr, ada002Embedding, upsertPineconeEndpoint, arkRequest);\n\n  \n\nretrieval.upsert();\n\n}\n\n  \n\n@PostMapping(value = "/pinecone/query")\n\npublic ArkResponse query(ArkRequest arkRequest) {\n\n  \n\n//String namespace = arkRequest.getQueryParam("namespace");\n\nString query = arkRequest.getBody().getString("query");\n\nint  topK = arkRequest.getIntQueryParam("topK");\n\n  \n\n// Configure Pinecone\n\n// queryPineconeEndpoint.setNamespace(namespace);\n\n  \n\n// Step 1: Chain ==> Get Embeddings From Input & Then Query To Pinecone\n\nEdgeChain<WordEmbeddings> embeddingsChain =\n\nnew EdgeChain<>(ada002Embedding.embeddings(query, arkRequest));\n\n  \n\n// Step 2: Chain ==> Query Embeddings from Pinecone\n\nEdgeChain<List<WordEmbeddings>> queryChain =\n\nnew EdgeChain<>(queryPineconeEndpoint.query(embeddingsChain.get(), topK));\n\n  \n\n// Chain 3 ===> Our queryFn passes takes list and passes each response with base prompt to\n\n// OpenAI\n\nEdgeChain<List<ChatCompletionResponse>> gpt3Chain =\n\nqueryChain.transform(wordEmbeddings -> queryFn(wordEmbeddings, arkRequest));\n\n  \n\nreturn  gpt3Chain.getArkResponse();\n\n}\n')),(0,i.kt)("h2",{id:"jsonnet-for-the-code"},"JSONnet for the Code"),(0,i.kt)("p",null,"Data is at the heart of nearly every aspect of technology. Whether you're configuring software, managing infrastructure, or exchanging information between systems, having a clean and efficient way to structure and manipulate data is essential. This is where JSONnet steps in as a valuable tool."),(0,i.kt)("p",null,"JSONnet is a versatile and human-friendly programming language designed for one primary purpose: simplifying the way we work with structured data. At its core, JSONnet takes the familiar concept of JSON (JavaScript Object Notation), a widely-used format for data interchange, and elevates it to a whole new level of flexibility and expressiveness. It has a declarative way of defining and describing the prompts and chains. "),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"The JSONnet for the query")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},'local maxTokens = if(payload.keepMaxTokens == "true") then payload.maxTokens else 10000;\nlocal preset = |||\n                  Use the following pieces of context to answer the question at the end. If\n                  you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\n                |||;\nlocal context = if(payload.keepContext == "true") then payload.context else "";\nlocal prompt = std.join("\\n", [preset, context]);\n{\n    "maxTokens": maxTokens,\n    "preset" : preset,\n    "context": context,\n    "prompt": if(std.length(prompt) > xtr.parseNum(maxTokens)) then std.substr(prompt, 0, xtr.parseNum(maxTokens)) else prompt\n}\n')),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("inlineCode",{parentName:"p"},"maxTokens"),": This line of code is used to determine the maximum number of tokens that the bot should consider when generating a response. If  ",(0,i.kt)("inlineCode",{parentName:"p"},"keepMaxTokens"),'  in the payload is set to "true", then the  ',(0,i.kt)("inlineCode",{parentName:"p"},"maxTokens"),"  value from the payload is used. Otherwise, it defaults to 10000.")),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("inlineCode",{parentName:"p"},"preset"),": This is a string that contains the instructions for the bot. It tells the bot to use the provided context to answer the question at the end. If the bot doesn't know the answer, it should admit that it doesn't know instead of making up an answer.")),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("inlineCode",{parentName:"p"},"context"),": This line of code is used to determine whether the bot should consider the context from the payload when generating a response. If  ",(0,i.kt)("inlineCode",{parentName:"p"},"keepContext"),'  in the payload is set to "true", then the  ',(0,i.kt)("inlineCode",{parentName:"p"},"context"),"  value from the payload is used. Otherwise, it defaults to an empty string.")),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("inlineCode",{parentName:"p"},"prompt"),": This is where the preset and context are combined to create the final prompt for the bot. The  ",(0,i.kt)("inlineCode",{parentName:"p"},"std.join"),"  function is used to join the preset and context with a newline character in between.")),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"The Final object- This is the output of the script. It includes everything."))))}h.isMDXComponent=!0},3892:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/Endpoints-04db02becb9e99d9ce10a4614496386f.png"},5100:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/OpenAi-caf33559ffca936cf46002ddd9944813.png"},2381:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/Spring-39c1ff29580a37c1635ff7039e6f39a3.png"},4955:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/Upsert-b5a090ab79f833f8c87775867ada723e.png"},8633:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/postmantesting-2ba2f0533c24e3d7b0dddc5e66debc27.png"},2441:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/query-89e8f5e6f226c0b6a24b05bccddb7018.png"},3338:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/springjpa-22ec39432582f02ac6c13eb270309d0c.png"}}]);